{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'problem_unittests'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-57f814ccae68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mproblem_unittests\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#import helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'problem_unittests'"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "from PIL import Image\n",
    "#import helper\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify appropriate transforms, and batch_sizes\n",
    "valid_transforms = transforms.Compose([transforms.Resize((50, 50)),\n",
    "                                    # transforms.CenterCrop(160),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                                                        [0.229, 0.224, 0.225])])\n",
    "\n",
    "data_dir = '/home/workspace/mortgage_face_real'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n",
    "\n",
    "# define datasets\n",
    "train_datasets = datasets.ImageFolder(train_dir, transform=valid_transforms)\n",
    "valid_datasets = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n",
    "test_datasets = datasets.ImageFolder(test_dir, transform=valid_transforms)\n",
    "\n",
    "# define data loaders\n",
    "trainloader = torch.utils.data.DataLoader(train_datasets, batch_size=32, shuffle=True)\n",
    "validloader = torch.utils.data.DataLoader(valid_datasets, batch_size=32)\n",
    "testloader = torch.utils.data.DataLoader(test_datasets, batch_size=32)\n",
    "\n",
    "loaders_scratch = dict()\n",
    "loaders_scratch['train'] = trainloader\n",
    "loaders_scratch['valid'] = validloader\n",
    "loaders_scratch['test'] = testloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# define VGG16 model\n",
    "VGG16 = models.vgg16(pretrained=True)\n",
    "\n",
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# move model to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    VGG16 = VGG16.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "\n",
    "for param in VGG16.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "drop_p = 0.1   \n",
    "\n",
    "classifier_dict = [('fc1', nn.Linear(512, 128)),\n",
    "                    ('relu1', nn.ReLU()),\n",
    "                    ('drop1', nn.Dropout(p=drop_p)),\n",
    "                    ('fc2', nn.Linear(128, 16)),\n",
    "                    ('relu2', nn.ReLU()),\n",
    "                    ('drop2', nn.Dropout(p=drop_p)),\n",
    "                    ('fc3', nn.Linear(16, 2)),\n",
    "                    #('output', nn.LogSoftmax(dim=1))\n",
    "                  ]\n",
    "\n",
    "classifier = nn.Sequential(OrderedDict(classifier_dict))\n",
    "    \n",
    "VGG16.classifier = classifier\n",
    "\n",
    "if use_cuda:\n",
    "    VGG16 = VGG16.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_detection_model = VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion_transfer = nn.CrossEntropyLoss()\n",
    "optimizer_transfer = optim.SGD(loan_detection_model.classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.690461 \tValidation Loss: 0.678276\n",
      "Validation loss decreased (inf --> 0.678276).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 0.680907 \tValidation Loss: 0.672813\n",
      "Validation loss decreased (0.678276 --> 0.672813).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 0.707830 \tValidation Loss: 0.667817\n",
      "Validation loss decreased (0.672813 --> 0.667817).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 0.686924 \tValidation Loss: 0.662233\n",
      "Validation loss decreased (0.667817 --> 0.662233).  Saving model ...\n",
      "Epoch: 13 \tTraining Loss: 0.674723 \tValidation Loss: 0.658576\n",
      "Validation loss decreased (0.662233 --> 0.658576).  Saving model ...\n",
      "Epoch: 16 \tTraining Loss: 0.660586 \tValidation Loss: 0.655474\n",
      "Validation loss decreased (0.658576 --> 0.655474).  Saving model ...\n",
      "Epoch: 19 \tTraining Loss: 0.661074 \tValidation Loss: 0.650291\n",
      "Validation loss decreased (0.655474 --> 0.650291).  Saving model ...\n",
      "Epoch: 22 \tTraining Loss: 0.639938 \tValidation Loss: 0.646778\n",
      "Validation loss decreased (0.650291 --> 0.646778).  Saving model ...\n",
      "Epoch: 25 \tTraining Loss: 0.654796 \tValidation Loss: 0.642858\n",
      "Validation loss decreased (0.646778 --> 0.642858).  Saving model ...\n",
      "Epoch: 28 \tTraining Loss: 0.699238 \tValidation Loss: 0.641698\n",
      "Validation loss decreased (0.642858 --> 0.641698).  Saving model ...\n",
      "Epoch: 31 \tTraining Loss: 0.654627 \tValidation Loss: 0.638133\n",
      "Validation loss decreased (0.641698 --> 0.638133).  Saving model ...\n",
      "Epoch: 34 \tTraining Loss: 0.643639 \tValidation Loss: 0.635695\n",
      "Validation loss decreased (0.638133 --> 0.635695).  Saving model ...\n",
      "Epoch: 37 \tTraining Loss: 0.625502 \tValidation Loss: 0.632874\n",
      "Validation loss decreased (0.635695 --> 0.632874).  Saving model ...\n",
      "Epoch: 40 \tTraining Loss: 0.613985 \tValidation Loss: 0.628412\n",
      "Validation loss decreased (0.632874 --> 0.628412).  Saving model ...\n",
      "Epoch: 43 \tTraining Loss: 0.635197 \tValidation Loss: 0.626647\n",
      "Validation loss decreased (0.628412 --> 0.626647).  Saving model ...\n",
      "Epoch: 46 \tTraining Loss: 0.632204 \tValidation Loss: 0.624627\n",
      "Validation loss decreased (0.626647 --> 0.624627).  Saving model ...\n",
      "Epoch: 49 \tTraining Loss: 0.674536 \tValidation Loss: 0.624573\n",
      "Validation loss decreased (0.624627 --> 0.624573).  Saving model ...\n",
      "Epoch: 52 \tTraining Loss: 0.689521 \tValidation Loss: 0.624006\n",
      "Validation loss decreased (0.624573 --> 0.624006).  Saving model ...\n",
      "Epoch: 55 \tTraining Loss: 0.638836 \tValidation Loss: 0.623928\n",
      "Validation loss decreased (0.624006 --> 0.623928).  Saving model ...\n",
      "Epoch: 58 \tTraining Loss: 0.647335 \tValidation Loss: 0.621926\n",
      "Validation loss decreased (0.623928 --> 0.621926).  Saving model ...\n",
      "Epoch: 61 \tTraining Loss: 0.638063 \tValidation Loss: 0.620532\n",
      "Validation loss decreased (0.621926 --> 0.620532).  Saving model ...\n",
      "Epoch: 64 \tTraining Loss: 0.595565 \tValidation Loss: 0.618027\n",
      "Validation loss decreased (0.620532 --> 0.618027).  Saving model ...\n",
      "Epoch: 67 \tTraining Loss: 0.624925 \tValidation Loss: 0.615094\n",
      "Validation loss decreased (0.618027 --> 0.615094).  Saving model ...\n",
      "Epoch: 70 \tTraining Loss: 0.624720 \tValidation Loss: 0.614122\n",
      "Validation loss decreased (0.615094 --> 0.614122).  Saving model ...\n",
      "Epoch: 73 \tTraining Loss: 0.599519 \tValidation Loss: 0.612605\n",
      "Validation loss decreased (0.614122 --> 0.612605).  Saving model ...\n",
      "Epoch: 76 \tTraining Loss: 0.658814 \tValidation Loss: 0.613082\n",
      "Epoch: 79 \tTraining Loss: 0.642978 \tValidation Loss: 0.611483\n",
      "Validation loss decreased (0.612605 --> 0.611483).  Saving model ...\n",
      "Epoch: 82 \tTraining Loss: 0.617025 \tValidation Loss: 0.608943\n",
      "Validation loss decreased (0.611483 --> 0.608943).  Saving model ...\n",
      "Epoch: 85 \tTraining Loss: 0.566236 \tValidation Loss: 0.606459\n",
      "Validation loss decreased (0.608943 --> 0.606459).  Saving model ...\n",
      "Epoch: 88 \tTraining Loss: 0.606568 \tValidation Loss: 0.604507\n",
      "Validation loss decreased (0.606459 --> 0.604507).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            ## record the average training loss, using something like\n",
    "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(data)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += (1 / (batch_idx + 1)) * (loss.data - train_loss)\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## update the average validation loss\n",
    "            \n",
    "            output = model(data)\n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            valid_loss += (1 / (batch_idx + 1)) * (loss.data - valid_loss)\n",
    "\n",
    "        \n",
    "        if epoch % 3 == 1:\n",
    "            # print training/validation statistics \n",
    "            print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "                epoch, \n",
    "                train_loss,\n",
    "                valid_loss\n",
    "                ))\n",
    "\n",
    "            ## TODO: save the model if validation loss has decreased\n",
    "            if valid_loss <= valid_loss_min:\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss))\n",
    "\n",
    "                torch.save(model.state_dict(), save_path)\n",
    "                valid_loss_min = valid_loss\n",
    "            \n",
    "    # return trained model\n",
    "    return model\n",
    "\n",
    "# train the model\n",
    "# loan_detection_model = train(90, loaders_scratch, loan_detection_model, optimizer_transfer, \n",
    "#                      criterion_transfer, use_cuda, 'loan_detection_model.pt')\n",
    "loan_detection_model = train(90, loaders_scratch, loan_detection_model, optimizer_transfer, \n",
    "                      criterion_transfer, use_cuda, 'loan_detection_model2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'loan_detection_model2.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6804f4da9275>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load the model that got the best validation accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# loan_detection_model.load_state_dict(torch.load('loan_detection_model.pt'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloan_detection_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loan_detection_model2.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'loan_detection_model2.pt'"
     ]
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy\n",
    "# loan_detection_model.load_state_dict(torch.load('loan_detection_model.pt'))\n",
    "loan_detection_model.load_state_dict(torch.load('loan_detection_model2.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.831689\n",
      "\n",
      "\n",
      "Test Accuracy: 61% (21/34)\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "# call test function    \n",
    "test(loaders_scratch, loan_detection_model, criterion_transfer, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('loan', 64.52)\n"
     ]
    }
   ],
   "source": [
    "class_names = [item for item in loaders_scratch['train'].dataset.classes]\n",
    "\n",
    "def load_image(img_path):    \n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_transforms = transforms.Compose([transforms.Resize((50, 50)),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize((0.485, 0.456, 0.406), \n",
    "                                                              (0.229, 0.224, 0.225))])\n",
    "\n",
    "    img = img_transforms(img)[:3,:,:].unsqueeze(0)\n",
    "    return img\n",
    "\n",
    "def predict_loan(model, img_path):\n",
    "    # load the image and return the predicted breed\n",
    "    img = load_image(img_path)\n",
    "    \n",
    "    if use_cuda:\n",
    "        model, img = model.cuda(), img.cuda()\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    outputs = model(img)\n",
    "    softmax_result = F.softmax(outputs, dim=1)\n",
    "    # print(round(torch.max(softmax_result.data, 1)[0].item() * 100, 2))\n",
    "    \n",
    "    \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    #idx = torch.argmax(model(img))\n",
    "    return class_names[predicted], round(torch.max(softmax_result.data, 1)[0].item() * 100, 2)\n",
    "\n",
    "# testing\n",
    "img_path = '/home/workspace/mortgage_faces/train/loan/187001.jpg'\n",
    "print(predict_loan(loan_detection_model, img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the application with real datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f1be8ab25072>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/workspace/Image/Sample2.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mrun_app\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/workspace/Image/Sample1.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-f1be8ab25072>\u001b[0m in \u001b[0;36mrun_app\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m## handle cases for a human face, dog, and neither\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "def run_app(img_path):\n",
    "    ## handle cases for a human face, dog, and neither\n",
    "    print(\"Hello!\")\n",
    "    img = Image.open(img_path)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    loan_flag, confident = predict_loan(loan_detection_model, img_path)\n",
    "    if loan_flag == 'loan':\n",
    "        print('You are going to loan. Confident: ' + str(confident) + '%')\n",
    "    else:\n",
    "        print('You are not going to loan. Confident: ' + str(confident) + '%')\n",
    "        \n",
    "        \n",
    "    print('\\n')\n",
    "\n",
    "img_path = '/home/workspace/Image/Sample2.jpg'        \n",
    "run_app(img_path)\n",
    "\n",
    "img_path = '/home/workspace/Image/Sample1.jpg'        \n",
    "run_app(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backup Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def VGG16_predict(img_path):\n",
    "    \n",
    "    image = Image.open(img_path) #.convert('RGB')\n",
    "    # size = (224, 224)\n",
    "    size = (50, 50)\n",
    "    \n",
    "    in_transform = transforms.Compose([\n",
    "                        transforms.Resize(size),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.485, 0.456, 0.406), \n",
    "                                             (0.229, 0.224, 0.225))])\n",
    "    \n",
    "    image = in_transform(image)[:3,:,:].unsqueeze(0)\n",
    "    \n",
    "    if use_cuda:\n",
    "        image = image.cuda()\n",
    "        \n",
    "    output = int(torch.max(VGG16(image), 1)[1][0])\n",
    "    \n",
    "    return output # predicted class index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(VGG16_predict('/home/workspace/processed_celeba_small/celeba/190960.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    '''Takes in a module and initializes all linear layers with weight\n",
    "       values taken from a normal distribution.'''\n",
    "    \n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model\n",
    "    # m.weight.data shoud be taken from a normal distribution\n",
    "    # m.bias.data should be 0\n",
    "    if classname.find('Linear') != -1:\n",
    "        # get the number of the inputs\n",
    "        n = m.in_features\n",
    "        y = 1.0/np.sqrt(n)\n",
    "        m.weight.data.normal_(0, y)\n",
    "        m.bias.data.fill_(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
